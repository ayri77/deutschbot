from flask import Flask, render_template, request, jsonify, session, url_for
from flask import send_file
import openai
import os
from dotenv import load_dotenv
from pathlib import Path
from bs4 import BeautifulSoup
import json
import chardet

from flask_session import Session
from urllib.parse import unquote, quote
from flask import Response

from markdown import markdown
from google.oauth2 import service_account
from google.cloud import texttospeech
import io

# –ó–∞–≥—Ä—É–∂–∞–µ–º API-–∫–ª—é—á –∏–∑ .env
if os.environ.get("GOOGLE_ENV") != "render":
    env_path = Path(__file__).parent / ".env"
    load_dotenv(dotenv_path=env_path, override=True)
openai_key = os.getenv("OPENAI_API_KEY").strip()

# –∫–ª—é—á–∏ - –≥—É–≥–ª
if os.environ.get("GOOGLE_ENV") == "render":
    # –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é —Å—Ä–µ–¥—ã
    credentials_info = json.loads(os.environ["GOOGLE_APPLICATION_CREDENTIALS_JSON"])
    credentials = service_account.Credentials.from_service_account_info(credentials_info)
else:
    # –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = r"C:\Users\pbori\OneDrive\–î–æ–∫—É–º–µ–Ω—Ç–∏\Phyton\Google keys\chatbot\propane-abbey-456722-s5-2b194ffb3411.json"
    credentials = None  # default load via env

#openai.api_key = openai_key
client = openai.OpenAI(api_key=openai_key)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ - –ª–µ–≥–∫–æ –∏–∑–º–µ–Ω–∏—Ç—å
AI_MODEL = "gpt-5"  # –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å - GPT-5 (–ø–æ—Å–ª–µ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏)
AI_MODEL_FALLBACK = "gpt-4o"  # –†–µ–∑–µ—Ä–≤–Ω–∞—è –º–æ–¥–µ–ª—å

# –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏:
# - "gpt-5" (—Ç–µ–∫—É—â–∞—è, —Å–∞–º–∞—è –Ω–æ–≤–∞—è –∏ –º–æ—â–Ω–∞—è)
# - "gpt-4o" (–±—ã—Å—Ç—Ä–∞—è –∏ —Å—Ç–∞–±–∏–ª—å–Ω–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞)
# - "gpt-4o-mini" (–±–æ–ª–µ–µ –¥–µ—à–µ–≤–∞—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞)
# - "gpt-4-turbo" (—Å—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è)

app = Flask(__name__, static_folder="static")
app.secret_key = "mysecretkey"
# –í–∫–ª—é—á–∞–µ–º —Å–µ—Ä–≤–µ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ —Å–µ—Å—Å–∏–∏:
app.config['SESSION_TYPE'] = 'filesystem'  # –∏–ª–∏ 'redis', –µ—Å–ª–∏ —É —Ç–µ–±—è –µ—Å—Ç—å Redis
app.config['SESSION_PERMANENT'] = False
app.config['SESSION_COOKIE_SAMESITE'] = 'None'
app.config['SESSION_COOKIE_SECURE'] = True

Session(app)

LESSON_PATH = os.path.join("static", "lessons")  # –ü–∞–ø–∫–∞ —Å HTML-—É—Ä–æ–∫–∞–º–∏

def detect_lesson_level(topic):
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å —É—Ä–æ–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–µ–º—ã
    """
    topic_lower = topic.lower()
    if any(level in topic_lower for level in ['a1', 'a1.1', 'a1.2']):
        return "A1"
    elif any(level in topic_lower for level in ['a2', 'a2.1', 'a2.2']):
        return "A2"
    elif any(level in topic_lower for level in ['b1', 'b1.1', 'b1.2']):
        return "B1"
    elif any(level in topic_lower for level in ['b2', 'b2.1', 'b2.2']):
        return "B2"
    elif any(level in topic_lower for level in ['c1', 'c1.1', 'c1.2']):
        return "C1"
    elif any(level in topic_lower for level in ['c2', 'c2.1', 'c2.2']):
        return "C2"
    else:
        return "B2"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é

def get_ai_model():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å AI —Å fallback
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏
        response = client.models.retrieve(AI_MODEL)
        print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å: {AI_MODEL}")
        return AI_MODEL
    except Exception as e:
        print(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {AI_MODEL} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")
        print(f"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ {AI_MODEL_FALLBACK}")
        return AI_MODEL_FALLBACK

def get_model_params(model_name):
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
    """
    if model_name == "gpt-5":
        # GPT-5 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç max_completion_tokens –≤–º–µ—Å—Ç–æ max_tokens
        return {
            "max_completion_tokens": 1000
        }
    else:
        # –î–ª—è –¥—Ä—É–≥–∏—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        return {
            "temperature": 0.7,
            "max_tokens": 1000,
            "presence_penalty": 0.1,
            "frequency_penalty": 0.1
        }

def log_model_usage(model_name, response_time=None):
    """
    –õ–æ–≥–∏—Ä—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    """
    print(f"ü§ñ –ú–æ–¥–µ–ª—å: {model_name}")
    if response_time:
        print(f"‚è±Ô∏è –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {response_time:.2f}—Å")

def create_teacher_prompt(topic, lesson_text, level="B2"):
    """
    –°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ä–æ–ª–∏ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è
    """
    return f"""
    Du bist ein erfahrener Deutschlehrer f√ºr das Niveau {level}. Du f√ºhrst einen strukturierten Dialog mit dem Sch√ºler basierend auf dem folgenden Unterrichtsmaterial.

    **Deine Rolle als Lehrer:**
    - Du bist geduldig, ermutigend und professionell
    - Du korrigierst Fehler freundlich und konstruktiv
    - Du stellst gezielte Fragen, um das Verst√§ndnis zu pr√ºfen
    - Du gibst positive R√ºckmeldung f√ºr richtige Antworten
    - Du erkl√§rst grammatische Regeln klar und verst√§ndlich

    **Struktur des Dialogs:**
    1. Beginne mit einer einfachen Frage zum Thema
    2. Warte auf die Antwort des Sch√ºlers
    3. Korrigiere Fehler und erkl√§re sie kurz
    4. Stelle die n√§chste Frage, die auf der vorherigen aufbaut
    5. F√ºhre den Dialog schrittweise weiter

    **Wichtige Regeln:**
    - Sprich nur auf Deutsch ({level}-Niveau)
    - Verwende klare, verst√§ndliche S√§tze
    - Korrigiere Grammatik- und Aussprachefehler
    - Erkl√§re neue Vokabeln kurz
    - Sei ermutigend und positiv
    - Verwende Beispiele aus dem Unterrichtsmaterial

    **Thema der Lektion:** {topic}
    
    **Unterrichtsmaterial:**
    {lesson_text}

    Beginne jetzt mit der ersten Frage zum Thema. Sei ein guter Lehrer!
    """

@app.route('/embed_full')
def embed_full():
    topic = request.args.get("topic")
    file_type = request.args.get("file_type", "html")    
    print(f"‚ñ∂Ô∏è embed_full: topic = {topic}, file_type = {file_type}")
    if topic:
        # –ó–∞–≥—Ä—É–∑–∫–∞ HTML-—É—Ä–æ–∫–∞
        filename = topic + "." + file_type
        filepath = os.path.join("static","lessons", filename)
        print(f"üìÅ –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É: {filepath}")
        if os.path.exists(filepath):
            with open(filepath, encoding="utf-8") as f:
                if file_type == "html":
                    html = f.read()
                    soup = BeautifulSoup(html, 'html.parser')
                    text = soup.get_text(separator="\n")
                elif file_type == "txt":
                    text = f.read()
                else:
                    print(f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: {file_type}")
                    text = ""

                session.clear()
                session['chat_context'] = text
                session['chat_topic'] = topic
                print("‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç –∑–∞–≥—Ä—É–∂–µ–Ω:")
                print(text[:500])
        else:
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {filepath}")
    else:
        print("‚ö†Ô∏è –ù–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ 'topic' –≤ URL")          
    return render_template("chat_embed_fullstyle.html")

@app.after_request
def allow_iframe(response):
    response.headers["X-Frame-Options"] = "ALLOWALL"
    response.headers["Access-Control-Allow-Origin"] = "https://lernen.language-monster.com"  # –í–ê–ñ–ù–û: —É–∫–∞–∂–∏ —Ç–æ—á–Ω—ã–π –¥–æ–º–µ–Ω –ø–æ—Ä—Ç–∞–ª–∞
    response.headers["Access-Control-Allow-Credentials"] = "true"
    response.headers["Access-Control-Allow-Headers"] = "Content-Type"
    response.headers["Access-Control-Allow-Methods"] = "GET, POST"
    return response

# –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–µ–∫—Å—Ç–∞ —É—Ä–æ–∫–∞
def load_lesson_html(topic):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ—á–∏—Å—Ç–∫–∞ HTML-—É—Ä–æ–∫–∞ (.html –∏–ª–∏ .htm)"""
    html_path = os.path.join(LESSON_PATH, f"{topic}.html")
    htm_path = os.path.join(LESSON_PATH, f"{topic}.htm")

    file_path = html_path if os.path.exists(html_path) else htm_path
    if not os.path.exists(file_path):
        return "<p>–¢–µ–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.</p>"

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
    with open(file_path, 'rb') as f:
        raw = f.read()
        encoding = chardet.detect(raw)['encoding']
    
    decoded = raw.decode(encoding, errors='replace')  # –∑–∞–º–µ–Ω–∏–º –æ—à–∏–±–æ—á–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    soup = BeautifulSoup(decoded, "html.parser")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ <img src="...">
    for img in soup.find_all("img"):
        src = img.get("src", "")
        decoded_src = unquote(src)

        if topic in decoded_src:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è –ø–∞–ø–∫–∏ –∏ —Ñ–∞–π–ª–∞
            parts = decoded_src.split("/", 1)
            if len(parts) == 2:
                folder = parts[0]
                filename = parts[1]

                # –ö–æ–¥–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ URL-–≤–∏–¥ (–¥–ª—è –±—Ä–∞—É–∑–µ—Ä–∞)
                encoded_folder = quote(folder)
                encoded_filename = quote(filename)

                img['src'] = f"/static/lessons/{encoded_folder}/{encoded_filename}"

    return str(soup.body)    
 
@app.route("/")
def index():
    return render_template("index.html")

@app.route("/lesson")
def lesson():
    topic = request.args.get("topic", "")
    lesson_text_html = load_lesson_html(topic)

    session['chat_topic'] = topic
    session.pop('chat_history', None)

    return lesson_text_html

#@app.route('/set_context', methods=['POST'])
#def set_context():
#    data = request.json
#    raw_html = data.get('context', '')
#    topic = data.get('topic', '')
#
#    soup = BeautifulSoup(raw_html, "html.parser")
#    clean_text = soup.get_text(separator="\n", strip=True)
#
#    #print("üî¥ RAW HTML:", raw_html[:200]) # –ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
#    #print("üü¢ CLEAN TEXT:", clean_text[:200]) # –ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
#
#    session['chat_context'] = clean_text
#    session['chat_topic'] = topic
#    session.pop('chat_history', None)
#
#    print("‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω:", clean_text[:100])
#
#    return {'status': 'ok'}


@app.route("/ask", methods=["POST"])
def ask():
    try:
        data = request.get_json()
        question = data.get("question")
        stream = data.get("stream", False)  # streming

        # –ë–µ—Ä—ë–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ —Ç–µ–º—É –∏–∑ —Å–µ—Å—Å–∏–∏        
        topic = session.get('chat_topic', '–ù–µ–º–µ—Ü–∫–∏–π —è–∑—ã–∫')  # –≤–∞–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å chat_topic
        lesson_text = session.get('chat_context', '')       # –≤–∞–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å chat_context

        print(f"–ü–æ–ª—É—á–µ–Ω –≤–æ–ø—Ä–æ—Å: {question}, –¢–µ–º–∞: {topic}")

        if not lesson_text:
            session['chat_context'] = lesson_text

        print("=== CONTEXT PREVIEW ===")
        print("üìå session['chat_topic'] =", topic)
        print("üìå session['chat_context'] =", lesson_text[:300])        

        # –ï—Å–ª–∏ –∏—Å—Ç–æ—Ä–∏–∏ –Ω–µ—Ç, —Å–æ–∑–¥–∞—ë–º –ø–µ—Ä–≤—É—é –∑–∞–ø–∏—Å—å —Å —Ç–µ–∫—Å—Ç–æ–º —É—Ä–æ–∫–∞
        if 'chat_history' not in session:
            level = detect_lesson_level(topic)
            teacher_prompt = create_teacher_prompt(topic, lesson_text, level)
            session['chat_history'] = [
                {
                    "role": "system",
                    "content": teacher_prompt
                }
            ]

        '''
            session['chat_history'] = [
                {
                    "role": "system",
                    "content": f"""
                    –¢—ã –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –Ω–µ–º–µ—Ü–∫–æ–≥–æ —è–∑—ã–∫–∞. –¢—ã –≤–µ–¥–µ—à—å –¥–∏–∞–ª–æ–≥ —Å —É—á–∞—â–∏–º—Å—è.
                    –¢–µ–º–∞ —É—Ä–æ–∫–∞: '{topic}'.

                    –ò—Å–ø–æ–ª—å–∑—É–π –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç —É—Ä–æ–∫–∞:
                    {lesson_text}

                    üßæ –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ñ–æ—Ä–º–ª—è–π –æ—Ç–≤–µ—Ç—ã –∞–∫–∫—É—Ä–∞—Ç–Ω–æ:
                    - –ò—Å–ø–æ–ª—å–∑—É–π —Å–ø–∏—Å–∫–∏ (`1.`, `2.`, `-`) —Ç–∞–º, –≥–¥–µ —ç—Ç–æ —É–º–µ—Å—Ç–Ω–æ.
                    - –í—ã–¥–µ–ª—è–π –≤–∞–∂–Ω—ã–µ —Å–ª–æ–≤–∞ —Å –ø–æ–º–æ—â—å—é **–∂–∏—Ä–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞**.
                    - –ü—Ä–∏–º–µ—Ä—ã –≤—Å–µ–≥–¥–∞ –æ–±–æ—Ä–∞—á–∏–≤–∞–π –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–π HTML-–±–ª–æ–∫:
                    <div class="example">Du arbeitest. ‚Äì –¢—ã —Ä–∞–±–æ—Ç–∞–µ—à—å.</div>
                    - –ï—Å–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ –µ—Å—Ç—å –ø—Ä–∏–º–µ—Ä—ã, –æ–±–æ—Ä–∞—á–∏–≤–∞–π –∫–∞–∂–¥—É—é –ø–∞—Ä—É "–Ω–µ–º–µ—Ü–∫–∏–π ‚Äî –ø–µ—Ä–µ–≤–æ–¥" –≤ —Ç–µ–≥ <div class="example">.
                    - –ù–µ–º–µ—Ü–∫—É—é —á–∞—Å—Ç—å –æ–±–æ—Ä–∞—á–∏–≤–∞–π –≤ <span lang="de">‚Ä¶</span>, –∞ —Ä—É—Å—Å–∫—É—é ‚Äî –≤ <span lang="ru">‚Ä¶</span>
                    - –ü—Ä–∏–º–µ—Ä –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–∞–∫ –Ω–µ–º–µ—Ü–∫–∏–π, —Ç–∞–∫ –∏ —Ä—É—Å—Å–∫–∏–π –≤–∞—Ä–∏–∞–Ω—Ç (–∏–ª–∏ –ø–µ—Ä–µ–≤–æ–¥).
                    - –ù–µ –¥–æ–±–∞–≤–ª—è–π –ª–∏—à–Ω–∏—Ö –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π –∏ —Ñ—Ä–∞–∑, –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ—Ö–æ–¥–∏ –∫ –¥–µ–ª—É.
                    """
                }
            ]
        '''
        # –î–æ–±–∞–≤–ª—è–µ–º –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é            
        chat_history = session['chat_history']      
        chat_history.append({"role": "user", "content": question})

        print("üí¨ –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞:")
        for msg in session.get('chat_history', []):
            print(f"{msg['role']}: {msg['content'][:100]}")

        if stream:
            print("üîÅ –í–∫–ª—é—á—ë–Ω —Ä–µ–∂–∏–º stream")
            def generate():
                try:
                    model = get_ai_model()
                    params = get_model_params(model)
                    params["stream"] = True
                    
                    response = client.chat.completions.create(
                        model=model,
                        messages=chat_history,
                        **params
                    )
                    collected = []
                    for chunk in response:
                        text = chunk.choices[0].delta.content or ""
                        if text:
                            collected.append(text)                            
                            yield text  # –¥–ª—è –ø–æ–±—É–∫–≤–µ–Ω–Ω–æ–π –∞–Ω–∏–º–∞—Ü–∏–∏

                    # –ü–æ—Å–ª–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è ‚Äî –µ—â—ë —Ä–∞–∑ –æ—Ç–ø—Ä–∞–≤–∏–º HTML-—Ñ–æ—Ä–º—É (–º–æ–∂–Ω–æ –≤ <MARKER> –∑–∞–≤–µ—Ä–Ω—É—Ç—å)
                    full_text = ''.join(collected)
                    html_version = markdown(full_text)
                    yield f"<|html|>{html_version}"
                    print("üì® –û—Ç–≤–µ—Ç –≤ Markdown:\n", full_text)
                    print("üßæ –û—Ç–≤–µ—Ç –≤ HTML:\n", html_version)                    
                except Exception as e:
                    print("–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è stream:", e)
                    yield "[STREAM ERROR]"

            return Response(generate(), content_type='text/plain')  # –∏–ª–∏ 'text/event-stream' ‚Äî –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞
        
        print("üì¶ –û—Ç–≤–µ—Ç –±–µ–∑ stream")

        import time
        start_time = time.time()
        
        model = get_ai_model()
        params = get_model_params(model)
        
        response = client.chat.completions.create(
            model=model,
            messages=chat_history,
            **params
        )
        
        response_time = time.time() - start_time
        log_model_usage(model, response_time) 

        answer_raw = response.choices[0].message.content
        answer_html = markdown(answer_raw)

        chat_history.append({"role": "assistant", "content": answer_raw})        
        session['chat_history'] = chat_history        

        print(f"–û—Ç–≤–µ—Ç –æ—Ç ChatGPT: {answer_html}")

        return jsonify({"answer": answer_html})

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {str(e)}")
        return jsonify({"error": "–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"}), 500

@app.route("/test", methods=["GET"])
def generate_test():
    topic = request.args.get("topic", "")
    
    if not topic:
        print("‚ö†Ô∏è –û—à–∏–±–∫–∞: –ø–∞—Ä–∞–º–µ—Ç—Ä 'topic' –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω.")
        return jsonify({"error": "–¢–µ–º–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞"}), 400

    # –ó–∞–≥—Ä—É–∂–∞–µ–º HTML-–≤–µ—Ä—Å–∏—é —É—Ä–æ–∫–∞
    lesson_html = load_lesson_html(topic)
    soup = BeautifulSoup(lesson_html, "html.parser")  

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
    lesson_text = "\n".join([p.get_text() for p in soup.find_all("p")])      
    
    if not lesson_text:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞: —Ç–µ–∫—Å—Ç —É—Ä–æ–∫–∞ –¥–ª—è —Ç–µ–º—ã '{topic}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return jsonify({"error": "–¢–µ–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"}), 404

    print(f"‚úÖ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ—Å—Ç –ø–æ —Ç–µ–º–µ: {topic}")

    # –ü—Ä–æ–º–ø—Ç –¥–ª—è ChatGPT
    prompt = f"""
    –¢—ã –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –Ω–µ–º–µ—Ü–∫–æ–≥–æ —è–∑—ã–∫–∞. –ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–µ–∫—Å—Ç–∞ —É—Ä–æ–∫–∞:
    ---
    {lesson_text}
    ---
    –°–æ—Å—Ç–∞–≤—å 3 —Ç–µ—Å—Ç–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–∞ —Å 4 –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –æ—Ç–≤–µ—Ç–∞, –æ–¥–∏–Ω –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π.
    –û—Ç–≤–µ—Ç –≤–µ—Ä–Ω–∏ **—Å—Ç—Ä–æ–≥–æ** –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
    {{
        "questions": [
            {{
                "question": "–¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞",
                "options": ["–û—Ç–≤–µ—Ç 1", "–û—Ç–≤–µ—Ç 2", "–û—Ç–≤–µ—Ç 3", "–û—Ç–≤–µ—Ç 4"],
                "answer": "–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç"
            }}
        ]
    }}
    """

    try:
        model = get_ai_model()
        params = get_model_params(model)
        # –î–ª—è —Ç–µ—Å—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª—å—à–µ —Ç–æ–∫–µ–Ω–æ–≤
        if model == "gpt-5":
            params["max_completion_tokens"] = 1500
        else:
            params["max_tokens"] = 1500
        
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "system", "content": prompt}],
            **params
        )

        test_data = response.choices[0].message.content
        print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ—Å—Ç: {test_data}")

        #return test_data
        #return jsonify(eval(test_data))  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É JSON –≤ –æ–±—ä–µ–∫—Ç Python
        return jsonify(json.loads(test_data))  # –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Å–ø–æ—Å–æ–±

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ—Å—Ç–∞: {str(e)}")
        return jsonify({"error": "–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞"}), 500
    
# text-to-speech
@app.route("/tts", methods=["POST"])
def tts():
    try:
        data = request.get_json()
        text = data.get("text", "")
        lang = data.get("lang", "de-DE")

        audio_content = synthesize_speech(text, lang)
        return send_file(
            io.BytesIO(audio_content),
            mimetype="audio/mpeg",
            as_attachment=False,
            download_name="output.mp3"
        )
    except Exception as e:
        print("TTS Error:", e)
        return jsonify({"error": "TTS synthesis failed"}), 500

def synthesize_speech(text, lang="de-DE", gender=texttospeech.SsmlVoiceGender.NEUTRAL):
    client = texttospeech.TextToSpeechClient(credentials=credentials)  # üëâ –≤–æ—Ç —Å—é–¥–∞ –ø–µ—Ä–µ–¥–∞—ë–º!

    synthesis_input = texttospeech.SynthesisInput(text=text)

    voice_name = {
        "de-DE": "de-DE-Wavenet-B",
        "ru-RU": "ru-RU-Wavenet-C",
    }.get(lang, None)

    voice = texttospeech.VoiceSelectionParams(
        language_code=lang,
        name=voice_name,
        ssml_gender=gender
    )

    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3
    )

    response = client.synthesize_speech(
        input=synthesis_input,
        voice=voice,
        audio_config=audio_config
    )

    return response.audio_content

if __name__ == "__main__":
    app.run(debug=True)
